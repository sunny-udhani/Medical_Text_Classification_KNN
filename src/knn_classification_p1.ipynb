{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medical abstracts describe the current conditions of a patient. Doctors routinely scan dozens or hundreds of abstracts each day as they do their rounds in a hospital and must quickly pick up on the salient information pointing to the patientâ€™s malady. You are trying to design assistive technology that can identify, with high precision, the class of problems described in the abstract. In the given dataset, abstracts from 5 different conditions have been included: digestive system diseases, cardiovascular diseases, neoplasms, nervous system diseases, and general pathological conditions.\n",
    "\n",
    "* Choose appropriate techniques for modeling text.\n",
    "* Implement the k-nearest neighbor classifier (cannot use libraries for this algorithm).\n",
    "* Use your version of the k-NN classifier to assign classes to medical texts.\n",
    "* Think about dealing with imbalanced data.\n",
    "* Evaluate results using the F1 Scoring Metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility to read data as panda dataframe\n",
    "\n",
    "def give_me_a_frame(data_location):\n",
    "    return pd.read_csv(\n",
    "        filepath_or_buffer=data_location, \n",
    "        header=None, \n",
    "        sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility to perform preprocessing tests\n",
    "\n",
    "def preprocess(statements):\n",
    "\n",
    "    s = set(stopwords.words('english'))\n",
    "    stemmer = WordNetLemmatizer()\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    digit_table = str.maketrans('', '', string.digits)\n",
    "    \n",
    "    result = []\n",
    "    for statement in statements:\n",
    "#       after lowercasing the sentence, remove digits, stopwords and lematization\n",
    "        \n",
    "        statement = statement.lower()\n",
    "        temp = list(filter(lambda w: not w in s,statement.split()))\n",
    "        stripped_punc_fix = [w.translate(table) for w in temp]\n",
    "        stripped_digit_fix = [w.translate(digit_table) for w in stripped_punc_fix]\n",
    "        stripped_wordlen_fix = [d for d in stripped_digit_fix if len(d) > 1]\n",
    "        stripped_stemmer_fix = [stemmer.lemmatize(stemmer_word) for stemmer_word in stripped_wordlen_fix]\n",
    "        result.append(\" \".join(stripped_stemmer_fix))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility to transform a bag of words to csr-matrix\n",
    "\n",
    "def build_matrix(train, test, n):\n",
    "    vectorizer = TfidfVectorizer(norm='l2'\n",
    "                                 ,ngram_range=(1,n)\n",
    "                                 ,min_df=3 \n",
    "                                )\n",
    "    return vectorizer.fit_transform(train),vectorizer.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility to predict output class of a single input object using k-nearest neighbors\n",
    "\n",
    "def predict_output(train_matrix, test_vector, train_classes,  k=3 ):\n",
    "    dot_product = test_vector.dot(train_matrix.T)\n",
    "    sims = list(zip(dot_product.indices, dot_product.data))\n",
    "    sims.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "#     take majority vote instead of using inverse similarity, decreased performance\n",
    "#     tc = Counter(train_classes[s[0]] for s in sims[:k]).most_common()\n",
    "#     if len(tc) < 2 or tc[0][1] > tc[1][1]:\n",
    "#             # majority vote\n",
    "#             return tc[0][0]\n",
    "\n",
    "    tc = defaultdict(float)\n",
    "    for s in sims[:k]:\n",
    "                tc[train_classes[s[0]]] += s[1]\n",
    "    return sorted(tc.items(), key=lambda x: x[1], reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(mat, cls, fold=1, d=10):\n",
    "    r\"\"\" Split the matrix and class info into train and test data using d-fold hold-out\n",
    "    \"\"\"\n",
    "    n = mat.shape[0]\n",
    "    r = int(np.ceil(n*1.0/d))\n",
    "    print(r)\n",
    "    mattr = []\n",
    "    clstr = []\n",
    "    # split mat and cls into d folds\n",
    "    for f in range(d):\n",
    "#         if f+1 != fold:\n",
    "            mattr.append( mat[f*r: min((f+1)*r, n)] )\n",
    "            clstr.extend( cls[f*r: min((f+1)*r, n)] )\n",
    "#     print(mattr)\n",
    "    # join all fold matrices that are not the test matrix\n",
    "    train = sp.vstack(mattr)\n",
    "    # extract the test matrix and class values associated with the test rows\n",
    "#     test = mat[(fold-1)*r: min(fold*r, n), :]\n",
    "#     clste = cls[(fold-1)*r: min(fold*r, n)]\n",
    "\n",
    "    return train, clstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peform steps on the train data to view evaluation\n",
    "\n",
    "def classify(statements, statements_test, classes, c, k):\n",
    "    \n",
    "    statements = preprocess(statements)\n",
    "    statements_test = preprocess(statements_test)\n",
    "    classes = np.array(classes)\n",
    "    X_Train, X_test = build_matrix(statements,statements_test,c)\n",
    "    \n",
    "#   fix unbalanced data set\n",
    "    nm = SMOTE(random_state=21)\n",
    "    X_res, y_res = nm.fit_sample(X_Train, classes)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.33, random_state=21)\n",
    "    y_pred = [predict_output(X_train,x,y_train,k) for x in X_test]\n",
    "    print(precision_recall_fscore_support(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The goal is to develop predictive models that can determine, given a particular medical abstract, which one of 5 classes it belongs to. As such, the goal would be to develop the best classification model, with the restriction that only use your own implementation of the k-NN classifier. There are many choices in text pre-processing and modeling, proximity measures, and classifier meta-parameters that will lead to many different solutions for the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = give_me_a_frame('../data/train.dat')   \n",
    "df = pd.DataFrame(df[0].str.split('\\t', 1).tolist())\n",
    "statements = df[1]\n",
    "classes = df[0]\n",
    "\n",
    "# n, bins, patches = plt.hist(classes)\n",
    "# plt.show()\n",
    "\n",
    "df = give_me_a_frame('../data/test.dat')\n",
    "statements_test = df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['catheterization laboratory event hospital outcome direct angioplasty acute myocardial infarction ass safety direct infarct angioplasty without antecedent thrombolytic therapy catheterization laboratory hospital event assessed consecutively treated patient infarction involving left anterior descending patient right circumflex coronary artery group patient similar age left anterior descending coronary artery year right coronary artery year circumflex coronary artery year patient multivessel disease left anterior descending coronary artery right coronary artery circumflex coronary artery patient initial grade antegrade flow left anterior descending coronary artery right coronary artery circumflex coronary artery cardiogenic shock present eight patient infarction left anterior descending coronary artery four infarction right coronary artery four infarction circumflex coronary artery major catheterization laboratory event cardioversion cardiopulmonary resuscitation dopamine intraaortic balloon pump support hypotension urgent surgery occurred patient infarction left anterior descending coronary artery eight infarction right coronary artery four infarction circumflex coronary artery shock six nonshock patient le one inlaboratory death shock patient infarction left anterior descending coronary artery']\n"
     ]
    }
   ],
   "source": [
    "statements = preprocess(statements)\n",
    "statements_test = preprocess(statements_test)\n",
    "classes = np.array(classes)\n",
    "# df = pd.DataFrame({'aaj':statements})\n",
    "\n",
    "print(statements[:1])\n",
    "# df[df['aaj'].str.contains('acut')]\n",
    "\n",
    "\n",
    "X_Train, X_test = build_matrix(statements,statements_test,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nm = SMOTE(random_state=21)\n",
    "X_res, y_res = nm.fit_sample(X_Train, classes)\n",
    "labels, values = zip(*Counter(y_res).most_common())\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.33, random_state=21)\n",
    "# X_train, x_test, y_train, y_test = train_test_split(X_Train, classes, test_size=0.33, random_state=21)\n",
    "\n",
    "# # X_train.append(x_test)\n",
    "X_train = sp.vstack([X_train,x_test])\n",
    "# # y_train.extend(y_test)\n",
    "y_train = np.append(y_train,y_test)\n",
    "# # y_pred = [predict_output(X_train,x,y_train,8) for x in X_test]\n",
    "# print(X_train.shape[0])\n",
    "# print(y_train.shape[0])\n",
    "\n",
    "with open('out.dat', 'w') as f:\n",
    "    for i in range(X_test.shape[0]):\n",
    "        f.write(\"%s\\n\" % (predict_output(X_train, X_test[i], y_train, 73)))\n",
    "        \n",
    "# clspr = [predict_output(X_Train, x_test, classes, 5) for x_test in X_test]\n",
    "# print(clspr)\n",
    "# aaj = cosine_similarity(X_test[:1],X_Train).flatten()\n",
    "# kal = X_test[:1].dot(X_Train.T)\n",
    "# similar_docs = aaj.argsort()[:-6:-1]\n",
    "# statements = np.array(statements)\n",
    "# classes = np.array(classes)\n",
    "# print(similar_docs)\n",
    "# print(classes[similar_docs])\n",
    "# print(kal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(2,3):\n",
    "    for k in range(73,74):\n",
    "        classify(statements, statements_test, classes, c, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
